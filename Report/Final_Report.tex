\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{nohyperref}
\usepackage{float}
\newcommand{\BibTeX}{\textrm{B \kern -.05em \textsc{i \kern -.025em b} \kern -.08em
T \kern -.1667em \lower .7ex \hbox{E} \kern -.125emX}}
\begin{document}

    \title{Mining Massive Data Sets Endterm Report}

    \author{
        \IEEEauthorblockN{1\textsuperscript{st} Luong Canh Phong}
        \IEEEauthorblockA{
            \textit{Faculty of Information Technology} \\
            \textit{Ton Duc Thang University}\\
            Ho Chi Minh City, Vietnam \\
            522H0036@student.tdtu.edu.com
        }
        \and
        \IEEEauthorblockN{2\textsuperscript{nd} Cao Nguyen Thai Thuan}
        \IEEEauthorblockA{
            \textit{Faculty of Information Technology} \\
            \textit{Ton Duc Thang University}\\ \
            Ho Chi Minh City, Vietnam \\
            522H0092@student.tdtu.edu.com
        }
        \and
        \IEEEauthorblockN{3\textsuperscript{rd} Tang Minh Thien An}
        \IEEEauthorblockA{
            \textit{Faculty of Information Technology} \\
            \textit{Ton Duc Thang University}\\
            Ho Chi Minh City, Vietnam \\
            522H0075@student.tdtu.edu.com
        }
        \and
        \IEEEauthorblockN{4\textsuperscript{th} Truong Tri Phong}
        \IEEEauthorblockA{
            \textit{Faculty of Information Technology} \\
            \textit{Ton Duc Thang University}\\
            Ho Chi Minh City, Vietnam \\
            522H0167@student.tdtu.edu.com
        }
        \and
        \IEEEauthorblockN{5\textsuperscript{th} Instructor: Nguyen Thanh An}
        \IEEEauthorblockA{
            \textit{Faculty of Information Technology} \\
            \textit{Ton Duc Thang University}\\
            Ho Chi Minh City, Vietnam \\
            nguyenthanhan@tdtu.edu.com
        }
    }

    \maketitle

    \begin{abstract}
        This project implements and evaluates key techniques in mining massive datasets.
        It covers hierarchical agglomerative clustering of string shingles using Jaccard distance; PySpark-based linear regression for gold price prediction;
        CUR decomposition for feature dimensionality reduction on gold price data; and PageRank analysis of the \texttt{it.tdtu.edu.vn} web graph using PySpark.
        The work demonstrates practical applications and provides insights into processing large-scale data.
    \end{abstract}


    \section{Introduction}
    \label{sec:introduction}
    The increasing volume of data requires efficient mining techniques.
    This project implements and analyzes four core algorithms: (1) hierarchical agglomerative clustering for non-Euclidean text data, using 4-shingles and Jaccard distance on alphabetical strings; (2) PySpark-based linear regression to predict Vietnamese gold prices from historical data; (3) CUR decomposition to reduce the dimensionality of gold price features (from 10 to 5) and assess its impact on regression; and (4) PageRank, implemented in PySpark, to identify influential pages within the \texttt{it.tdtu.edu.vn} web graph.
    Python and PySpark are utilized throughout.
    This report details the methodologies, implementations, and experimental results for each task.


    \section{First Task: Hierarchical clustering in non-Euclidean spaces}
    \label{sec:first-task}
    \input{sections/first-task}


    \section{Second Task: Linear Regression – Gold price prediction}
    \label{sec:second-task}
    \input{sections/second-task}


    \section{Third Task: CUR – Dimensionality Reduction}
    \label{sec:third-task}
    \input{sections/third-task}


    \section{Fourth Task: PageRanking – the Google algorithm}
    \label{sec:fourth-task}
    \input{sections/fourth-task}


    \section{Contribution}
    \label{sec:contribution}

    The following table represents the contribution of each member, note that whichever member handles whichever task will also write the report for that task.

    \begin{table}[h]
        \centering
        \caption{Member Contributions}
        \setlength{\tabcolsep}{2pt} % Reduce column spacing
        \renewcommand{\arraystretch}{1} % Adjust row spacing
        \resizebox{\linewidth}{!}{ % Fit within column width
            \begin{tabular}{|l|c|c|c|}
                \hline
                \textbf{ID} & \textbf{Member}       & \textbf{Contribution}      & \textbf{Progress} \\
                \hline
                522H0036    & Luong Canh Phong      & Task 2 and Handling Report & 100\%             \\
                522H0092    & Cao Nguyen Thai Thuan & Task 4 and Report Support  & 100\%             \\
                522H0075    & Tang Minh Thien An    & Task 3                     & 100\%             \\
                522H0167    & Truong Tri Phong      & Task 1                     & 100\%             \\
                \hline
            \end{tabular}
        }
        \label{tab:contributions}
    \end{table}


    \section{Self-evaluation}
    \label{sec:self-evaluation}

    The following table is our self-evaluation on our tasks:

    \begin{table}[h]
        \centering
        \caption{Self-evaluation}
        \setlength{\tabcolsep}{2pt} % Reduce column spacing
        \renewcommand{\arraystretch}{1} % Adjust row spacing
        \resizebox{\linewidth}{!}{ % Fit within column width
            \begin{tabular}{|l|c|c|c|}
                \hline
                \textbf{Task} & \textbf{Task Requirements}                      & \textbf{Completion Ratio} \\
                \hline
                Task 1        & Hierarchical clustering in non-Euclidean spaces & 90\%                      \\
                Task 2        & Linear Regression – Gold price prediction       & 100\%                     \\
                Task 3        & CUR – Dimensionality Reduction                  & 90\%                      \\
                Task 4        & PageRanking – the Google algorithm              & 100\%                     \\
                Task 5        & Report                                          & 100\%                     \\
                \hline
            \end{tabular}
        }
        \label{tab:self-evaluation}
    \end{table}


    \section{Conclusion}
    \label{sec:conclusion}
%    We have gone through a variety of techniques and algorithms used in the world of data mining.
%    For the first task, we have to find same-day customers and utilize the A-Priori algorithm to find frequent pairs of customers that shop on the same date and save the output of each pass in a dedicated folder.
%    As we run though the code, the result after sorting is a reasonable ascending list of frequent customer pairs.
%    For the second task, store the given dataset locally and identify baskets, as well as implementing the PCY algorithm to find frequent pairs along with generating metadata with predetermined constraints, the results for this task are two separate lists, one containing all frequent pairs, and the other is a list of association rules based on the user's given support threshold and confidence value.
%    And finally, implement and compare between a traditional and an alternative MinHashLSH function to understand and have a greater insight into how the frequent pairs searching is done.
%    We can see that with a slight modification and a different way of merging, it can result in a notably higher efficiency and better results.

    \begin{thebibliography}{00}
%        \bibitem{b12} Tpoint Tech, ``Apriori Algorithm, ''\\\
%        [Online]. Available: \href{https://www.tpointtech.com/apriori-algorithm}{https://www.tpointtech.com/apriori-algorithm}
%        \bibitem{b6} Databricks, ``MapReduce, '' Databricks Glossary, 2025.\\\
%        [Online]. Available: \href{https://www.databricks.com/glossary/mapreduce}{https://www.databricks.com/glossary/mapreduce}
%        \bibitem{b1} J. S. Park and M. S. Chen, ``Using a hash table to eliminate candidates in a frequent itemset mining algorithm, '' \textit{IEEE Trans. Knowl. Data Eng.}, vol. 7, no. 3, pp. 464--472, 1995.
%        \bibitem{b2} J. Han, J. Pei, and Y. Yin, ``Mining frequent patterns without candidate generation, '' \textit{ACM SIGMOD Rec.}, vol. 29, no. 2, pp. 1--12, 2000.
%        \bibitem{b3} PySpark Documentation, ``PySpark API Documentation, '' 2025.\\\
%        [Online]. Available: \url{https://spark.apache.org/docs/latest/api/python}
%        \bibitem{b4} PySpark Documentation, ``pyspark.ml.feature.MinHashLSH, '' Apache Spark, 2025.\\\
%        [Online]. Available: \href{https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.MinHashLSH}{https://spark.apache.org/docs/latest/api/python/refer\-ence/api/pyspark.ml.feature.MinHashLSH}
%        \bibitem{b5} Amazon Web Services, ``Jaccard similarity, '' AWS Neptune Analytics Documentation, 2024.\\\
%        [Online]. Available: \href{https://docs.aws.amazon.com/neptune-analytics/latest/userguide/jaccard-similarity.html}{https://docs.aws.amazon.com/neptune-analytics/latest/userguide/jaccard-similarity.html}
    \end{thebibliography}
\end{document}